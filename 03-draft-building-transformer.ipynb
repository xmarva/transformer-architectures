{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install -q torchdata==0.3.0 torchtext==0.12 spacy==3.2 altair GPUtil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:48:55.570618Z","iopub.execute_input":"2025-02-14T21:48:55.570845Z","iopub.status.idle":"2025-02-14T21:50:13.795849Z","shell.execute_reply.started":"2025-02-14T21:48:55.570825Z","shell.execute_reply":"2025-02-14T21:50:13.794961Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ['TORCHDYNAMO_DISABLE'] = '1' ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:13.796781Z","iopub.execute_input":"2025-02-14T21:50:13.797019Z","iopub.status.idle":"2025-02-14T21:50:13.801168Z","shell.execute_reply.started":"2025-02-14T21:50:13.796981Z","shell.execute_reply":"2025-02-14T21:50:13.800376Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport time\nimport math\nimport copy\nimport spacy\nimport GPUtil\nimport pandas as pd\nfrom typing import *\nfrom itertools import chain\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom torch.optim.lr_scheduler import LambdaLR\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nfrom torch.utils.data import DataLoader, Dataset\n\nimport altair as alt\nfrom altair import Chart\n\nalt.data_transformers.disable_max_rows()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:13.801931Z","iopub.execute_input":"2025-02-14T21:50:13.802235Z","iopub.status.idle":"2025-02-14T21:50:31.534432Z","shell.execute_reply.started":"2025-02-14T21:50:13.802208Z","shell.execute_reply":"2025-02-14T21:50:31.533643Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DataTransformerRegistry.enable('default')"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Используемое устройство: {device}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.535136Z","iopub.execute_input":"2025-02-14T21:50:31.535366Z","iopub.status.idle":"2025-02-14T21:50:31.540015Z","shell.execute_reply.started":"2025-02-14T21:50:31.535348Z","shell.execute_reply":"2025-02-14T21:50:31.539163Z"}},"outputs":[{"name":"stdout","text":"Используемое устройство: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    def __init__(self, features, eps=1e-6):\n        super().__init__()\n        self.gamma = nn.Parameter(torch.ones(features))\n        self.beta = nn.Parameter(torch.zeros(features))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim=True)\n        std = x.std(-1, keepdim=True)\n        return self.gamma * (x - mean) / (std + self.eps) + self.beta","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.540819Z","iopub.execute_input":"2025-02-14T21:50:31.541071Z","iopub.status.idle":"2025-02-14T21:50:31.559236Z","shell.execute_reply.started":"2025-02-14T21:50:31.541051Z","shell.execute_reply":"2025-02-14T21:50:31.558555Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class ResidualConnection(nn.Module):\n    def __init__(self, size, dropout):\n        super().__init__()\n        self.norm = LayerNorm(size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, sublayer):\n        return x + self.dropout(sublayer(self.norm(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.561677Z","iopub.execute_input":"2025-02-14T21:50:31.561922Z","iopub.status.idle":"2025-02-14T21:50:31.575038Z","shell.execute_reply.started":"2025-02-14T21:50:31.561904Z","shell.execute_reply":"2025-02-14T21:50:31.574380Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def attention(query, key, value, mask=None, dropout=None):\n    d_k = query.size(-1)\n    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n    \n    if mask is not None:\n        scores = scores.masked_fill(mask == 0, -1e9)\n        \n    p_attn = F.softmax(scores, dim=-1)\n    if dropout is not None:\n        p_attn = dropout(p_attn)\n        \n    return torch.matmul(p_attn, value), p_attn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.576418Z","iopub.execute_input":"2025-02-14T21:50:31.576611Z","iopub.status.idle":"2025-02-14T21:50:31.587908Z","shell.execute_reply.started":"2025-02-14T21:50:31.576594Z","shell.execute_reply":"2025-02-14T21:50:31.587297Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, h, d_model, dropout=0.1):\n        super().__init__()\n        assert d_model % h == 0\n        self.d_k = d_model // h\n        self.h = h\n        self.linears = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(4)])\n        self.dropout = nn.Dropout(p=dropout)\n\n    def forward(self, query, key, value, mask=None):\n        if mask is not None:\n            mask = mask.unsqueeze(1)\n            \n        batch_size = query.size(0)\n        \n        query, key, value = [\n            lin(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n            for lin, x in zip(self.linears, (query, key, value))\n        ]\n        \n        x, self.attn = attention(query, key, value, mask=mask, dropout=self.dropout)\n        \n        x = x.transpose(1, 2).contiguous() \\\n             .view(batch_size, -1, self.h * self.d_k)\n             \n        return self.linears[-1](x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.588725Z","iopub.execute_input":"2025-02-14T21:50:31.588959Z","iopub.status.idle":"2025-02-14T21:50:31.602682Z","shell.execute_reply.started":"2025-02-14T21:50:31.588928Z","shell.execute_reply":"2025-02-14T21:50:31.602088Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class PositionwiseFeedForward(nn.Module):\n    def __init__(self, d_model, d_ff, dropout=0.1):\n        super().__init__()\n        self.w1 = nn.Linear(d_model, d_ff)\n        self.w2 = nn.Linear(d_ff, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        return self.w2(self.dropout(F.relu(self.w1(x))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.603521Z","iopub.execute_input":"2025-02-14T21:50:31.603802Z","iopub.status.idle":"2025-02-14T21:50:31.619977Z","shell.execute_reply.started":"2025-02-14T21:50:31.603775Z","shell.execute_reply":"2025-02-14T21:50:31.619301Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class Embeddings(nn.Module):\n    def __init__(self, d_model, vocab):\n        super().__init__()\n        self.lut = nn.Embedding(vocab, d_model)\n        self.d_model = d_model\n\n    def forward(self, x):\n        return self.lut(x) * math.sqrt(self.d_model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.620627Z","iopub.execute_input":"2025-02-14T21:50:31.620844Z","iopub.status.idle":"2025-02-14T21:50:31.634252Z","shell.execute_reply.started":"2025-02-14T21:50:31.620827Z","shell.execute_reply":"2025-02-14T21:50:31.633595Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, dropout, max_len=5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n        \n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n                             (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1)].detach()\n        return self.dropout(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.634894Z","iopub.execute_input":"2025-02-14T21:50:31.635109Z","iopub.status.idle":"2025-02-14T21:50:31.651232Z","shell.execute_reply.started":"2025-02-14T21:50:31.635079Z","shell.execute_reply":"2025-02-14T21:50:31.650602Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self, size, self_attn, feed_forward, dropout):\n        super().__init__()\n        self.self_attn = self_attn\n        self.feed_forward = feed_forward\n        self.sublayer = nn.ModuleList([ResidualConnection(size, dropout) for _ in range(2)])\n        self.size = size\n\n    def forward(self, x, mask):\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n        return self.sublayer[1](x, self.feed_forward)\n\nclass Encoder(nn.Module):\n    def __init__(self, layer, N):\n        super().__init__()\n        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(N)])\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self, x, mask):\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.norm(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.651944Z","iopub.execute_input":"2025-02-14T21:50:31.652241Z","iopub.status.idle":"2025-02-14T21:50:31.673099Z","shell.execute_reply.started":"2025-02-14T21:50:31.652214Z","shell.execute_reply":"2025-02-14T21:50:31.672381Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n        super().__init__()\n        self.size = size\n        self.self_attn = self_attn\n        self.src_attn = src_attn\n        self.feed_forward = feed_forward\n        self.sublayer = nn.ModuleList([ResidualConnection(size, dropout) for _ in range(3)])\n\n    def forward(self, x, memory, src_mask, tgt_mask):\n        m = memory\n        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n        return self.sublayer[2](x, self.feed_forward)\n\nclass Decoder(nn.Module):\n    def __init__(self, layer, N):\n        super().__init__()\n        self.layers = nn.ModuleList([copy.deepcopy(layer) for _ in range(N)])\n        self.norm = LayerNorm(layer.size)\n        \n    def forward(self, x, memory, src_mask, tgt_mask):\n        for layer in self.layers:\n            x = layer(x, memory, src_mask, tgt_mask)\n        return self.norm(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.673769Z","iopub.execute_input":"2025-02-14T21:50:31.673947Z","iopub.status.idle":"2025-02-14T21:50:31.682858Z","shell.execute_reply.started":"2025-02-14T21:50:31.673931Z","shell.execute_reply":"2025-02-14T21:50:31.682004Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.src_embed = src_embed\n        self.tgt_embed = tgt_embed\n        self.generator = generator\n        \n    def encode(self, src, src_mask):\n        return self.encoder(self.src_embed(src), src_mask)\n    \n    def decode(self, memory, src_mask, tgt, tgt_mask):\n        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n    \n    def forward(self, src, tgt, src_mask, tgt_mask):\n        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n\ndef make_model(src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1):\n    c = copy.deepcopy\n    attn = MultiHeadAttention(h, d_model)\n    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n    position = PositionalEncoding(d_model, dropout)\n    \n    model = Transformer(\n        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n        nn.Linear(d_model, tgt_vocab)\n    )\n    \n    for p in model.parameters():\n        if p.dim() > 1:\n            nn.init.xavier_uniform_(p)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.683616Z","iopub.execute_input":"2025-02-14T21:50:31.683883Z","iopub.status.idle":"2025-02-14T21:50:31.700353Z","shell.execute_reply.started":"2025-02-14T21:50:31.683857Z","shell.execute_reply":"2025-02-14T21:50:31.699706Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class Batch:\n    def __init__(self, src, tgt=None, pad=0):\n        self.src = src\n        self.src_mask = (src != pad).unsqueeze(-2)\n        if tgt is not None:\n            self.tgt = tgt[:, :-1]\n            self.tgt_y = tgt[:, 1:]\n            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n            self.ntokens = (self.tgt_y != pad).data.sum()\n\n    @staticmethod\n    def make_std_mask(tgt, pad):\n        tgt_mask = (tgt != pad).unsqueeze(-2)\n        seq_len = tgt.size(-1)\n        look_ahead_mask = torch.tril(torch.ones(seq_len, seq_len)).bool()\n        return tgt_mask & look_ahead_mask.to(tgt.device)\n\ndef data_gen(V, batch, nbatches):\n    for _ in range(nbatches):\n        data = torch.randint(1, V, (batch, 10))\n        data[:, 0] = 1\n        src = data.clone()\n        tgt = data.clone()\n        yield Batch(src, tgt, 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.700981Z","iopub.execute_input":"2025-02-14T21:50:31.701182Z","iopub.status.idle":"2025-02-14T21:50:31.717731Z","shell.execute_reply.started":"2025-02-14T21:50:31.701165Z","shell.execute_reply":"2025-02-14T21:50:31.716972Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class SimpleLossCompute:\n    def __init__(self, generator, criterion):\n        self.generator = generator\n        self.criterion = criterion\n        \n    def __call__(self, x, y, norm):\n        x = self.generator(x)\n        loss = self.criterion(x.reshape(-1, x.size(-1)), \n                             y.reshape(-1)) / norm\n        return loss.data * norm, loss\n\ndef run_epoch(data_iter, model, loss_compute, optimizer=None, scheduler=None):\n    total_loss = 0\n    total_tokens = 0\n    \n    for i, batch in enumerate(data_iter):\n        out = model(batch.src, batch.tgt, \n                   batch.src_mask, batch.tgt_mask)\n                   \n        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n        \n        if optimizer is not None:\n            optimizer.zero_grad()\n            loss_node.backward()\n            optimizer.step()\n            if scheduler is not None:\n                scheduler.step()\n\n        total_loss += loss\n        total_tokens += batch.ntokens\n        \n    return total_loss / total_tokens","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.718545Z","iopub.execute_input":"2025-02-14T21:50:31.718813Z","iopub.status.idle":"2025-02-14T21:50:31.736571Z","shell.execute_reply.started":"2025-02-14T21:50:31.718788Z","shell.execute_reply":"2025-02-14T21:50:31.735882Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def example_synthetic():\n    V = 11\n    model = make_model(V, V, N=2)\n    criterion = nn.CrossEntropyLoss(ignore_index=0)\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n    \n    batch_size = 80\n    for epoch in range(20):\n        model.train()\n        run_epoch(data_gen(V, batch_size, 20), model, \n                 SimpleLossCompute(model.generator, criterion), \n                 optimizer)\n        \n        model.eval()\n        loss = run_epoch(data_gen(V, batch_size, 5), model, \n                        SimpleLossCompute(model.generator, criterion), \n                        None)\n        print(f\"Epoch {epoch+1} | Loss: {loss:.2f}\")\n    \n    model.eval()\n    src = torch.tensor([[1,2,3,4,5,6,7,8,9,10]], dtype=torch.long)\n    src_mask = torch.ones(1, 1, 10, dtype=torch.bool)\n    memory = model.encode(src, src_mask)\n    ys = torch.zeros(1, 1).type_as(src)\n    \n    for i in range(9):\n        out = model.decode(memory, src_mask, \n                          ys, \n                          Batch.make_std_mask(ys, 0))\n        prob = model.generator(out[:, -1])\n        _, next_word = torch.max(prob, dim=1)\n        ys = torch.cat([ys, next_word.unsqueeze(1)], dim=1)\n    \n    print(\"Example Output:\", ys)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.737248Z","iopub.execute_input":"2025-02-14T21:50:31.737506Z","iopub.status.idle":"2025-02-14T21:50:31.750693Z","shell.execute_reply.started":"2025-02-14T21:50:31.737488Z","shell.execute_reply":"2025-02-14T21:50:31.749947Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#example_synthetic()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:50:31.751450Z","iopub.execute_input":"2025-02-14T21:50:31.751666Z","iopub.status.idle":"2025-02-14T21:50:31.769559Z","shell.execute_reply.started":"2025-02-14T21:50:31.751645Z","shell.execute_reply":"2025-02-14T21:50:31.768891Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"import os\nimport time\nimport math\nimport copy\nfrom itertools import chain\nfrom typing import Optional, Tuple\n\nimport spacy\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom torch.optim.lr_scheduler import LambdaLR\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torch.nn.utils.rnn import pad_sequence\nfrom datasets import load_dataset\n\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nfrom torch.nn.parallel import DistributedDataParallel as DDP\n\nimport altair as alt\nfrom altair import Chart","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:53:06.031578Z","iopub.execute_input":"2025-02-14T21:53:06.031954Z","iopub.status.idle":"2025-02-14T21:53:07.141740Z","shell.execute_reply.started":"2025-02-14T21:53:06.031921Z","shell.execute_reply":"2025-02-14T21:53:07.141058Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"print(\"🚀 Загрузка Tatoeba en-ru...\")\ntry:\n    dataset = load_dataset(\n        \"Helsinki-NLP/tatoeba\",\n        lang1=\"en\", \n        lang2=\"ru\",\n        trust_remote_code=True\n    )\nexcept Exception as e:\n    print(f\"❌ Ошибка: {e}\")\n    raise\n\nprint(\"\\n🔍 Структура датасета:\")\nprint(dataset)\nprint(\"\\nПример данных:\")\nfor i in range(2):\n    print(f\"EN: {dataset['train'][i]['translation']['en']}\")\n    print(f\"RU: {dataset['train'][i]['translation']['ru']}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:53:08.299643Z","iopub.execute_input":"2025-02-14T21:53:08.300182Z","iopub.status.idle":"2025-02-14T21:53:26.389472Z","shell.execute_reply.started":"2025-02-14T21:53:08.300155Z","shell.execute_reply":"2025-02-14T21:53:26.388605Z"}},"outputs":[{"name":"stdout","text":"🚀 Загрузка Tatoeba en-ru...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.93k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"557638752ab44d778a8790171b34d9ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tatoeba.py:   0%|          | 0.00/4.41k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f584db69eb0c4f0480576be04f3fe792"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/14.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e92cd2fc5884410599eacbd6a7ec2ce3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7a0e5bc062346008ace443bb1ad4525"}},"metadata":{}},{"name":"stdout","text":"\n🔍 Структура датасета:\nDatasetDict({\n    train: Dataset({\n        features: ['id', 'translation'],\n        num_rows: 523656\n    })\n})\n\nПример данных:\nEN: For once in my life I'm doing a good deed... And it is useless.\nRU: Один раз в жизни я делаю хорошее дело... И оно бесполезно.\n\nEN: Let's try something.\nRU: Давайте что-нибудь попробуем!\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"spacy_en = spacy.blank('en')\nspacy_ru = spacy.blank('ru')\n\ndef tokenize(text, lang):\n    try:\n        return [tok.text.lower() for tok in lang.tokenizer(text) if tok.text.strip()]\n    except:\n        return []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:53:26.390531Z","iopub.execute_input":"2025-02-14T21:53:26.390764Z","iopub.status.idle":"2025-02-14T21:53:26.678092Z","shell.execute_reply.started":"2025-02-14T21:53:26.390744Z","shell.execute_reply":"2025-02-14T21:53:26.677268Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"MAX_LENGTH = 40\nSAMPLE_SIZE = 5000 \n\nprint(f\"\\n🔧 Обработка первых {SAMPLE_SIZE} примеров...\")\n\ndef process_batch(batch):\n    # Извлекаем тексты из структуры translation с ключами 'en' и 'ru'\n    en_texts = [item['en'] for item in batch['translation']]\n    ru_texts = [item['ru'] for item in batch['translation']]\n    \n    processed = {'en_tokens': [], 'ru_tokens': []}\n    \n    for en, ru in zip(en_texts, ru_texts):\n        try:\n            en_toks = [tok.text.lower() for tok in spacy_en.tokenizer(en) if tok.text.strip()][:MAX_LENGTH]\n            ru_toks = [tok.text.lower() for tok in spacy_ru.tokenizer(ru) if tok.text.strip()][:MAX_LENGTH]\n        except Exception as e:\n            print(f\"Ошибка токенизации: {e}\")\n            continue\n        \n        if 3 <= len(en_toks) <= MAX_LENGTH and 3 <= len(ru_toks) <= MAX_LENGTH:\n            processed['en_tokens'].append(en_toks)\n            processed['ru_tokens'].append(ru_toks)\n    \n    return processed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:53:26.679587Z","iopub.execute_input":"2025-02-14T21:53:26.679801Z","iopub.status.idle":"2025-02-14T21:53:26.686271Z","shell.execute_reply.started":"2025-02-14T21:53:26.679783Z","shell.execute_reply":"2025-02-14T21:53:26.685621Z"}},"outputs":[{"name":"stdout","text":"\n🔧 Обработка первых 5000 примеров...\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"processed_data = dataset['train'].map(\n    process_batch,\n    batched=True,\n    batch_size=1000,\n    remove_columns=dataset['train'].column_names\n).filter(lambda x: len(x['en_tokens']) > 0)\n\nfinal_data = {\n    'en_tokens': processed_data['en_tokens'][:SAMPLE_SIZE],\n    'ru_tokens': processed_data['ru_tokens'][:SAMPLE_SIZE]\n}\n\nprint(f\"✅ Осталось примеров: {len(final_data['en_tokens'])}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:53:26.687473Z","iopub.execute_input":"2025-02-14T21:53:26.687733Z","iopub.status.idle":"2025-02-14T21:54:25.981710Z","shell.execute_reply.started":"2025-02-14T21:53:26.687708Z","shell.execute_reply":"2025-02-14T21:54:25.980607Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/523656 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4348f3f4aeb4a65ba419abb57b3795a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/521963 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb7b4b8fc7c54af2b4f3d787ec27c4c7"}},"metadata":{}},{"name":"stdout","text":"✅ Осталось примеров: 5000\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"from collections import defaultdict\n\ndef build_compact_vocab(tokens_list, max_vocab=8000):\n    counter = Counter()\n    for tokens in tokens_list:\n        counter.update(tokens)\n    \n    vocab = ['<pad>', '<sos>', '<eos>', '<unk>'] + [tok for tok, cnt in counter.most_common(max_vocab-4)]\n    token_to_idx = defaultdict(lambda: 3, {tok:i for i, tok in enumerate(vocab)})\n    return token_to_idx, vocab  # Теперь возвращаем и словарь, и список\n\nprint(\"\\n📘 Создаем словари...\")\nen_vocab, en_vocab_list = build_compact_vocab(final_data['en_tokens'])\nru_vocab, ru_vocab_list = build_compact_vocab(final_data['ru_tokens'])\n\nprint(f\"Размеры словарей:\")\nprint(f\"Английский: {len(en_vocab)}\")\nprint(f\"Русский: {len(ru_vocab)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T22:10:08.707043Z","iopub.execute_input":"2025-02-14T22:10:08.707433Z","iopub.status.idle":"2025-02-14T22:10:08.737217Z","shell.execute_reply.started":"2025-02-14T22:10:08.707398Z","shell.execute_reply":"2025-02-14T22:10:08.736238Z"}},"outputs":[{"name":"stdout","text":"\n📘 Создаем словари...\nРазмеры словарей:\nАнглийский: 3135\nРусский: 6096\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"print(\"Топ-10 частых токенов:\")\nprint(\"EN:\", list(en_vocab.keys())[4:14])  # Пропускаем служебные\nprint(\"RU:\", list(ru_vocab.keys())[4:14])\n\n\ndef coverage(vocab, tokens_list):\n    total = sum(len(t) for t in tokens_list)\n    covered = sum(len([t for t in tokens if t in vocab]) for tokens in tokens_list)\n    return covered / total\n\nprint(f\"EN Coverage: {coverage(en_vocab, final_data['en_tokens']):.2%}\")\nprint(f\"RU Coverage: {coverage(ru_vocab, final_data['ru_tokens']):.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T21:55:17.048289Z","iopub.execute_input":"2025-02-14T21:55:17.048625Z","iopub.status.idle":"2025-02-14T21:55:17.066429Z","shell.execute_reply.started":"2025-02-14T21:55:17.048597Z","shell.execute_reply":"2025-02-14T21:55:17.065738Z"}},"outputs":[{"name":"stdout","text":"Топ-10 частых токенов:\nEN: ['.', 'you', 'i', 'the', 'to', '?', 'a', 'your', 'is', 'do']\nRU: ['.', ',', '?', 'ты', 'я', 'не', 'в', 'что', 'вы', 'на']\nEN Coverage: 100.00%\nRU Coverage: 100.00%\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"class TranslationDataset(Dataset):\n    def __init__(self, en_tokens, ru_tokens, en_vocab, ru_vocab):\n        self.en_tokens = en_tokens\n        self.ru_tokens = ru_tokens\n        self.en_vocab = en_vocab\n        self.ru_vocab = ru_vocab\n        self.pad_idx = en_vocab['<pad>']\n\n    def __len__(self):\n        return len(self.en_tokens)\n\n    def __getitem__(self, idx):\n        en = [self.en_vocab['<sos>']] + \\\n             [self.en_vocab.get(tok, self.en_vocab['<unk>']) for tok in self.en_tokens[idx]] + \\\n             [self.en_vocab['<eos>']]\n        \n        ru = [self.ru_vocab['<sos>']] + \\\n             [self.ru_vocab.get(tok, self.ru_vocab['<unk>']) for tok in self.ru_tokens[idx]] + \\\n             [self.ru_vocab['<eos>']]\n        \n        return torch.LongTensor(en), torch.LongTensor(ru)\n\ndef collate_fn(batch):\n    en_batch, ru_batch = zip(*batch)\n    \n    en_padded = pad_sequence(en_batch, padding_value=en_vocab['<pad>'], batch_first=True)\n    ru_padded = pad_sequence(ru_batch, padding_value=ru_vocab['<pad>'], batch_first=True)\n    \n    return Batch(\n        src=en_padded,\n        tgt=ru_padded,\n        pad=en_vocab['<pad>']\n    )\n\nmodel = make_model(\n    src_vocab=len(en_vocab),\n    tgt_vocab=len(ru_vocab),\n    N=6,\n    d_model=512,\n    d_ff=2048,\n    h=8,\n    dropout=0.1).to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=ru_vocab['<pad>'])\noptimizer = optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\nscheduler = LambdaLR(optimizer, lr_lambda=lambda step: min(\n    (step + 1e-8)**-0.5,  # Добавляем epsilon чтобы избежать деления на ноль\n    (step + 1) * (4000**-1.5)  # Начинаем с шага 1\n))\n\ntrain_dataset = TranslationDataset(\n    final_data['en_tokens'],\n    final_data['ru_tokens'],\n    en_vocab,\n    ru_vocab\n)\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=128,\n    collate_fn=collate_fn,\n    shuffle=True,\n    num_workers=4\n)\n\ndef train_real_data(model, train_loader, epochs=20):\n    model.train()\n    best_loss = float('inf')\n    \n    for epoch in range(epochs):\n        start_time = time.time()\n        total_loss = 0\n        total_tokens = 0\n        \n        for i, batch in enumerate(train_loader):\n            batch = Batch(\n                src=batch.src.to(device),\n                tgt=batch.tgt.to(device),\n                pad=en_vocab['<pad>']\n            )\n            \n            optimizer.zero_grad()\n            output = model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n            \n            loss, loss_node = SimpleLossCompute(model.generator, criterion)(\n                output, batch.tgt_y, batch.ntokens\n            )\n            \n            loss_node.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n            \n            total_loss += loss\n            total_tokens += batch.ntokens\n            \n            if i % 50 == 0:\n                avg_loss = total_loss / total_tokens\n                print(f\"Epoch {epoch+1} | Batch {i} | Loss: {avg_loss:.4f}\")\n        \n        avg_loss = total_loss / total_tokens\n        if avg_loss < best_loss:\n            best_loss = avg_loss\n            torch.save(model.state_dict(), \"best_model.pth\")\n        \n        print(f\"Epoch {epoch+1} завершена | Loss: {avg_loss:.4f} | Время: {time.time()-start_time:.1f}s\")\n        \n        test_sentence = \"Hello world\"\n        translate(\n            model, \n            test_sentence, \n            en_vocab, \n            ru_vocab, \n            ru_vocab_list,  # Список должен быть создан заранее\n            spacy_en        # Токенизатор\n        )\n\ndef translate(model, sentence, en_vocab, ru_vocab, ru_vocab_list, spacy_tokenizer, max_len=50):\n    model.eval()\n    tokens = [tok.text.lower() for tok in spacy_tokenizer(sentence)]\n    \n    src = torch.LongTensor([\n        [en_vocab['<sos>']] + \n        [en_vocab.get(tok, en_vocab['<unk>']) for tok in tokens] + \n        [en_vocab['<eos>']\n    ]]).to(device)\n    \n    src_mask = (src != en_vocab['<pad>']).unsqueeze(-2)\n    \n    with torch.no_grad():\n        memory = model.encode(src, src_mask)\n    \n    ys = torch.ones(1, 1, dtype=torch.long).fill_(ru_vocab['<sos>']).to(device)\n    \n    for _ in range(max_len-1):\n        seq_len = ys.size(1)\n        look_ahead_mask = torch.tril(\n            torch.ones((seq_len, seq_len), dtype=torch.bool, device=device\n        ))\n        tgt_mask = (ys != ru_vocab['<pad>']).unsqueeze(-2) & look_ahead_mask\n        \n        with torch.no_grad():\n            out = model.decode(memory, src_mask, ys, tgt_mask)\n            prob = model.generator(out[:, -1])\n            _, next_word = torch.max(prob, dim=1)\n        \n        ys = torch.cat([ys, next_word.unsqueeze(1)], dim=1)\n        \n        if next_word == ru_vocab['<eos>']:\n            break\n    \n    translation = ' '.join([ru_vocab_list[idx] for idx in ys[0].cpu().numpy() \n                          if idx not in [ru_vocab['<sos>'], ru_vocab['<eos>']]])\n    print(f\"Перевод: '{translation}'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T22:13:46.123662Z","iopub.execute_input":"2025-02-14T22:13:46.124018Z","iopub.status.idle":"2025-02-14T22:13:46.683434Z","shell.execute_reply.started":"2025-02-14T22:13:46.123990Z","shell.execute_reply":"2025-02-14T22:13:46.682511Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using dvice: {device}\")\n\ntrain_real_data(model.to(device), train_loader, epochs=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-14T22:13:49.481215Z","iopub.execute_input":"2025-02-14T22:13:49.481524Z","iopub.status.idle":"2025-02-14T22:18:50.980069Z","shell.execute_reply.started":"2025-02-14T22:13:49.481502Z","shell.execute_reply":"2025-02-14T22:18:50.979127Z"}},"outputs":[{"name":"stdout","text":"Используемое устройство: cuda\nEpoch 1 | Batch 0 | Loss: 0.0085\nEpoch 1 завершена | Loss: 0.0087 | Время: 14.6s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима подходят придёшь неотразима взгляда неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят подходят подходят придёшь тоже подходят придёшь неотразима частично ну́жно подходят неотразима подходят подходят подходят подходят придёшь неотразима подходят придёшь неотразима частично частично частично'\nEpoch 2 | Batch 0 | Loss: 0.0085\nEpoch 2 завершена | Loss: 0.0087 | Время: 14.1s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима подходят придёшь неотразима взгляда неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят подходят подходят придёшь тоже подходят придёшь неотразима частично ну́жно подходят неотразима подходят подходят подходят подходят придёшь неотразима подходят придёшь неотразима частично частично частично'\nEpoch 3 | Batch 0 | Loss: 0.0082\nEpoch 3 завершена | Loss: 0.0087 | Время: 14.9s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима подходят придёшь неотразима сон взгляда неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят подходят подходят подходят придёшь тоже подходят придёшь неотразима подходят неотразима подходят подходят подходят подходят подходят подходят придёшь неотразима подходят придёшь частично частично частично'\nEpoch 4 | Batch 0 | Loss: 0.0085\nEpoch 4 завершена | Loss: 0.0087 | Время: 15.2s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима хожу наверно неотразима неотразима неотразима подходят придёшь неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят подходят подходят подходят подходят подходят придёшь неотразима частично ну́жно подходят неотразима подходят подходят подходят подходят подходят придёшь неотразима подходят придёшь частично подходят придёшь'\nEpoch 5 | Batch 0 | Loss: 0.0085\nEpoch 5 завершена | Loss: 0.0086 | Время: 14.9s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима хожу наверно неотразима неотразима неотразима подходят придёшь неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят подходят подходят подходят подходят подходят придёшь неотразима частично ну́жно подходят неотразима подходят подходят подходят подходят подходят придёшь неотразима подходят придёшь частично подходят придёшь'\nEpoch 6 | Batch 0 | Loss: 0.0083\nEpoch 6 завершена | Loss: 0.0086 | Время: 14.8s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима хожу наверно неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят подходят подходят подходят придёшь тоже подходят придёшь неотразима подходят неотразима подходят подходят подходят подходят подходят подходят придёшь неотразима подходят придёшь частично подходят придёшь'\nEpoch 7 | Batch 0 | Loss: 0.0085\nEpoch 7 завершена | Loss: 0.0086 | Время: 14.6s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима хожу взгляда неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят подходят подходят подходят придёшь тоже подходят придёшь неотразима подходят неотразима подходят подходят подходят подходят подходят придёшь неотразима подходят придёшь неотразима частично ну́жно придёшь'\nEpoch 8 | Batch 0 | Loss: 0.0086\nEpoch 8 завершена | Loss: 0.0086 | Время: 14.6s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима сон неотразима сон взгляда неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят подходят подходят подходят придёшь тоже заставляете взгляда неотразима ну́жно подходят неотразима подходят подходят подходят подходят подходят придёшь неотразима подходят придёшь пожилым подходят придёшь'\nEpoch 9 | Batch 0 | Loss: 0.0082\nEpoch 9 завершена | Loss: 0.0085 | Время: 15.1s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима сон неотразима сон взгляда неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят заставляете взгляда неотразима заставляете взгляда неотразима ну́жно ну́жно подходят неотразима подходят подходят подходят подходят подходят придёшь неотразима подходят придёшь пожилым подходят придёшь'\nEpoch 10 | Batch 0 | Loss: 0.0084\nEpoch 10 завершена | Loss: 0.0085 | Время: 14.9s\nПеревод: 'взгляда взгляда взгляда взгляда взгляда неотразима сон неотразима сон взгляда неотразима неотразима неотразима неотразима неотразима неотразима сон неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят заставляете взгляда неотразима сон взгляда неотразима ну́жно ну́жно ну́жно подходят придёшь тоже подходят подходят подходят придёшь неотразима подходят придёшь пожилым подходят придёшь'\nEpoch 11 | Batch 0 | Loss: 0.0081\nEpoch 11 завершена | Loss: 0.0085 | Время: 14.8s\nПеревод: 'взгляда взгляда взгляда взгляда неотразима сон неотразима сон взгляда неотразима сон неотразима неотразима неотразима неотразима сон неотразима сон неотразима неотразима неотразима неотразима неотразима неотразима подходят подходят подходят заставляете взгляда неотразима сон взгляда неотразима ну́жно ну́жно ну́жно подходят придёшь тоже подходят заставляете взгляда неотразима подходят придёшь пожилым подходят придёшь заставляете'\nEpoch 12 | Batch 0 | Loss: 0.0081\nEpoch 12 завершена | Loss: 0.0084 | Время: 14.7s\nПеревод: 'взгляда взгляда взгляда взгляда неотразима сон неотразима сон неотразима сон неотразима сон неотразима неотразима сон неотразима сон неотразима неотразима неотразима неотразима неотразима неотразима неотразима подходят неотразима подходят заставляете взгляда неотразима сон взгляда неотразима ну́жно ну́жно ну́жно подходят придёшь тоже подходят заставляете взгляда неотразима подходят придёшь пожилым подходят придёшь заставляете'\nEpoch 13 | Batch 0 | Loss: 0.0079\nEpoch 13 завершена | Loss: 0.0084 | Время: 14.7s\nПеревод: 'неотразима сон взгляда сон взгляда сон пожилым сон неотразима сон неотразима сон неотразима сон неотразима сон неотразима сон неотразима сон неотразима неотразима неотразима неотразима неотразима подходят взгляда неотразима сон пикник тоже сон взгляда ну́жно ну́жно ну́жно ну́жно подходят подходят заставляете взгляда неотразима подходят придёшь пожилым подходят придёшь пожилым заставляете'\nEpoch 14 | Batch 0 | Loss: 0.0083\nEpoch 14 завершена | Loss: 0.0083 | Время: 14.8s\nПеревод: 'неотразима сон взгляда сон пожилым сон пожилым сон неотразима сон неотразима сон неотразима сон неотразима сон неотразима сон неотразима сон неотразима сон неотразима неотразима неотразима лекарства пикник заставляете взгляда сон взгляда неотразима сон ну́жно ну́жно ну́жно ну́жно ну́жно ну́жно ну́жно ну́жно ну́жно ну́жно подходят придёшь пожилым ну́жно ну́жно ну́жно'\nEpoch 15 | Batch 0 | Loss: 0.0084\nEpoch 15 завершена | Loss: 0.0083 | Время: 15.1s\nПеревод: 'неотразима сон взгляда'\nEpoch 16 | Batch 0 | Loss: 0.0085\nEpoch 16 завершена | Loss: 0.0082 | Время: 14.9s\nПеревод: ''\nEpoch 17 | Batch 0 | Loss: 0.0085\nEpoch 17 завершена | Loss: 0.0082 | Время: 14.6s\nПеревод: ''\nEpoch 18 | Batch 0 | Loss: 0.0077\nEpoch 18 завершена | Loss: 0.0081 | Время: 14.6s\nПеревод: ''\nEpoch 19 | Batch 0 | Loss: 0.0086\nEpoch 19 завершена | Loss: 0.0081 | Время: 14.9s\nПеревод: ''\nEpoch 20 | Batch 0 | Loss: 0.0079\nEpoch 20 завершена | Loss: 0.0080 | Время: 14.7s\nПеревод: ''\n","output_type":"stream"}],"execution_count":56}]}