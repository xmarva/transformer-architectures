# Transformer Playground

To understand Transformer Architectures through practiceâ€”from implementing one from scratch to adapting pre-trained models (BERT, GPT). 

| Notebook | Concepts |
|---------|----------|
| 1. **Tokenization [Prototype]** [Going Modular] | BPE, HuggingFace Tokenizers, Collator |
| 2. **Transformer Architecture [Prototype]** [Going Modular] | Positional Encoding, Attention |
| 3. **Functions and Tools [Prototype]** [Going Modular] | Translation functions, Architecture improvements, Weights and Biases |
| 4. **Transformer Training [Prototype]** [Going Modular] | Training Loop |

---

## Progress

### Basic Components  
- [x] **Tokenization**
- [x] **Transformer Architecture**  
- [x] **Functions and Tools**
- [x] **Transformer Training**
- [ ] **Improvements and Experiments**

---

## Resources & References ðŸ“š  
*List is coming soon.*  

---

**Note**: This is a living projectâ€”code and structure may evolve.